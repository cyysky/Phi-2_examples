{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d908d6-d1d6-4bc8-b06a-f7d9628139fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 2\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n",
      "GPU 1: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "#thanks to this article\n",
    "#https://medium.com/@anoopjohny2000/building-a-text-generation-app-with-microsoft-phi-2-using-streamlit-90852afd1d65\n",
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# If CUDA is available, it means PyTorch can use the GPU\n",
    "if cuda_available:\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # List all available GPUs\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f89ee6f-7e61-458a-8726-e52768445ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\python\\python311\\lib\\site-packages (from ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\python\\python311\\lib\\site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\python\\python311\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\python\\python311\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\python\\python311\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\python\\python311\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "Using cached widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec7cb65-4ef1-467e-bf72-e12fd1a2a05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015f71c7c8a4dcea7c8f0b6587e975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# Load the Phi 2 model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", device_map=\"auto\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667d12ba-b0c6-424c-8074-4a72767233a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/a6/b9/44623bdb05595481107153182e7f4b9f2ef9d3b674938ad13842054dcbd8/accelerate-0.26.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python\\python311\\lib\\site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python\\python311\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\python\\python311\\lib\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\python\\python311\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\python\\python311\\lib\\site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\python\\python311\\lib\\site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python\\python311\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in c:\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "   ---------------------------------------- 0.0/270.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/270.9 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/270.9 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/270.9 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 270.9/270.9 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.26.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9822d7-1f9d-43e8-8ae6-9d92592c30aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: You must give at least one requirement to install (see \"pip help install\")\n"
     ]
    }
   ],
   "source": [
    "#!pip install -Uqqq\n",
    "\n",
    "\n",
    "#!pip -qqq install bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b980507-cf49-49a3-9768-e3b5622c459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 12:31:44.543 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Streamlit UI\n",
    "#st.title(\"Microsoft Phi 2 Streamlit App\")\n",
    "#prompt = st.text_area(\"Enter your prompt\", \"Give me a list of 13 words that have 9 letters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6756a85-35d4-4e32-af7e-402f234a7ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681cfa2f536349a886d0a0146899522b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='My Button', style=ButtonStyle())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import module \n",
    "import ipywidgets as widgets \n",
    "  \n",
    "# creating button \n",
    "widgets.Button(description = 'My Button') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146abf9d-ab31-43fb-8b9b-001518a219f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Code for generating output based on user input\n",
    "with torch.no_grad():\n",
    "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.3\n",
    "    )\n",
    "output = tokenizer.decode(output_ids[0][token_ids.size(1):])\n",
    "st.text(\"Generated Output:\")\n",
    "st.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cf270f-f64f-47a8-89e2-ef62786d2981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hope this email finds you well. I am writing to invite you to my birthday party next Saturday. It will be at my house from 6 pm to 10 pm. There will be food, drinks, music, and games. I would love to see you there and catch up with you. Please let me know if you can make it.\\nOutput: A possible response is:\\n\\nHi, I am doing great, thanks for asking. I am happy to hear from you and I am looking forward to your birthday party. It sounds like a lot of fun. I can make it next Saturday, no problem. See you then.\\n<|endoftext|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6311feac-6c94-4520-b9e5-28896fee633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44949e9ab48442d69f6edf73ca2a4a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lang()>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets \n",
    "from ipywidgets import interact, interact_manual, fixed \n",
    "  \n",
    "from random import choice \n",
    "  \n",
    "def lang(): \n",
    "  langSelect = [\"English\",\"Deustche\",\"Espanol\",\"Italiano\",\"한국어\",\"日本人\"] \n",
    "  print(choice(langSelect)) \n",
    "    \n",
    "interact_manual(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1995816a-4325-4280-aaea-f35f8b4fc2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48e2a2a84e244d5936009e62ab4d94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='my name is ', continuous_update=False, description='input_text'), Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.process_text(input_text)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact_manual\n",
    "# Create a text box\n",
    "text_box = widgets.Text(\n",
    "    description='Input:',\n",
    "    value='my name is '\n",
    ")\n",
    "# Define your function to be called when button is clicked\n",
    "def process_text(input_text):\n",
    "    # Replace this with the processing you want to do\n",
    "    print(\"You entered:\", input_text)\n",
    "    #Code for generating output based on user input\n",
    "    with torch.no_grad():\n",
    "        token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "        print(model.device)\n",
    "        output_ids = model.generate(\n",
    "            token_ids.to(model.device),\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=0.9\n",
    "        )\n",
    "    output = tokenizer.decode(output_ids[0][token_ids.size(1):])\n",
    "    print(output)\n",
    "\n",
    "# Create the UI using interact_manual\n",
    "interact_manual(process_text, input_text=text_box.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136f627-f7b7-4e40-858e-7baa150d6f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
